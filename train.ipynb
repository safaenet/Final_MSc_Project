{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1e2e4fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from dataset import ShapesDataset\n",
    "from prototypical_net import ConvNet\n",
    "from learn2learn.data import TaskDataset\n",
    "from learn2learn.data import MetaDataset\n",
    "from learn2learn.data.transforms import NWays, KShots, LoadData, RemapLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26adc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(84, scale=(0.5, 1.0)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n",
    "# ])\n",
    "\n",
    "# base_dataset = ShapesDataset(\"synthetic-shapes\", transform=transform)\n",
    "# meta_dataset = MetaDataset(base_dataset)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "dataset = ShapesDataset('synthetic-shapes', transform=transform)\n",
    "meta_dataset = MetaDataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e6f78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taskset = TaskDataset(\n",
    "#     meta_dataset,\n",
    "#     task_transforms=[\n",
    "#         NWays(meta_dataset, n=2),\n",
    "#         KShots(meta_dataset, k=10 * 2),\n",
    "#         LoadData(meta_dataset),\n",
    "#         RemapLabels(meta_dataset)\n",
    "#     ],\n",
    "#     num_tasks=1000,\n",
    "# )\n",
    "\n",
    "taskset = TaskDataset(\n",
    "    meta_dataset,\n",
    "    task_transforms=[\n",
    "        NWays(meta_dataset, n=2),\n",
    "        KShots(meta_dataset, k=10),\n",
    "        LoadData(meta_dataset),\n",
    "        RemapLabels(meta_dataset),\n",
    "    ],\n",
    "    num_tasks=1000\n",
    ")\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c6a358",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b5cd1684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Loss=0.3820, Accuracy=100.0000\n",
      "Iteration 100: Loss=0.0019, Accuracy=100.0000\n",
      "Iteration 200: Loss=0.0013, Accuracy=100.0000\n",
      "Iteration 300: Loss=0.0007, Accuracy=100.0000\n",
      "Iteration 400: Loss=0.0005, Accuracy=100.0000\n",
      "Iteration 500: Loss=0.0005, Accuracy=100.0000\n",
      "Iteration 600: Loss=0.0003, Accuracy=100.0000\n",
      "Iteration 700: Loss=0.0003, Accuracy=100.0000\n",
      "Iteration 800: Loss=0.0003, Accuracy=100.0000\n",
      "Iteration 900: Loss=0.0002, Accuracy=100.0000\n"
     ]
    }
   ],
   "source": [
    "n_ways = 2\n",
    "k_shot = 5  # support\n",
    "k_query = 5\n",
    "\n",
    "for iteration in range(1000):\n",
    "    try:\n",
    "        learner = model\n",
    "        task = taskset.sample()\n",
    "        data, labels = task\n",
    "        data, labels = data.to(device), labels.to(device)\n",
    "\n",
    "        embeddings = learner(data)\n",
    "\n",
    "        support = []\n",
    "        support_labels = []\n",
    "        query = []\n",
    "        query_labels = []\n",
    "\n",
    "        for class_idx in range(n_ways):\n",
    "            class_mask = labels == class_idx\n",
    "            class_indices = torch.nonzero(class_mask).squeeze()\n",
    "\n",
    "            if len(class_indices) < (k_shot + k_query):\n",
    "                print(f\"Not enough samples for class {class_idx}\")\n",
    "                continue\n",
    "\n",
    "            # Take first k_shot for support, rest for query\n",
    "            support_idx = class_indices[:k_shot]\n",
    "            query_idx = class_indices[k_shot:k_shot + k_query]\n",
    "\n",
    "            support.append(embeddings[support_idx])\n",
    "            support_labels.append(labels[support_idx])\n",
    "\n",
    "            query.append(embeddings[query_idx])\n",
    "            query_labels.append(labels[query_idx])\n",
    "\n",
    "        if len(support) < n_ways or len(query) < n_ways:\n",
    "            print(\"Skipping task — not enough valid classes\")\n",
    "            continue\n",
    "\n",
    "        support = torch.cat(support)\n",
    "        support_labels = torch.cat(support_labels)\n",
    "        query = torch.cat(query)\n",
    "        query_labels = torch.cat(query_labels)\n",
    "\n",
    "        # Compute prototypes\n",
    "        prototypes = []\n",
    "        for class_idx in range(n_ways):\n",
    "            class_mask = support_labels == class_idx\n",
    "            prototypes.append(support[class_mask].mean(0))\n",
    "        prototypes = torch.stack(prototypes)\n",
    "\n",
    "        dists = torch.cdist(query, prototypes)\n",
    "        predictions = -dists\n",
    "        loss = loss_fn(predictions, query_labels)\n",
    "\n",
    "        if torch.isnan(loss):\n",
    "            print(\"Loss is NaN — skipping iteration\")\n",
    "            continue\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        acc = (predictions.argmax(1) == query_labels).float().mean()\n",
    "        if iteration % 100 == 0:\n",
    "            print(f\"Iteration {iteration}: Loss={loss.item():.4f}, Accuracy={acc.item()*100:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in iteration {iteration}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83febc",
   "metadata": {},
   "source": [
    "### Save model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "680e6aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model.pth\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Model saved to model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
